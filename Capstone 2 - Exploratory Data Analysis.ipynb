{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5002dfb4",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c785ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb67615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv('Corona_NLP.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefd0234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OriginalTweet    How to make your last longer Mum shares her br...\n",
       "Sentiment                                       Extremely Positive\n",
       "Name: 43028, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True) #Something wonky happened while saving the dataframe to csv and two of the Sentiments were\n",
    "#saved as separate rows, creating a few NaNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c48f7e",
   "metadata": {},
   "source": [
    "Because this is a categorization problem, there isn't much EDA to be done until I tokenize and vectorize all of \n",
    "the words in the OriginalTweet column during the pre-processing stage of analysis. For now, I've simply produced a \n",
    "value count of the different sentiment scores, plotted it as a histogram, and assessed how well my own impression \n",
    "of the data coheres with the sentiment scores assigned by the dataset's creator using a hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd658fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29206d80",
   "metadata": {},
   "source": [
    "Interestingly, the value count skews toward the positive with more positive tweets than negative ones and \n",
    "more extremely positive tweets than extremely negative ones. Neutral tweets are also less common than positive and\n",
    "negative tweets, yielding a distribution with two peaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06da63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment'].value_counts().loc[['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']].plot.bar()\n",
    "plt.xlabel('Sentiment score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of sentiment scores')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527ca37",
   "metadata": {},
   "source": [
    "Assessment of sentiment depends on a variety of factors (e.g., cultural context, individual disposition, etc.). \n",
    "Therefore, it is important to determine whether and to what extent I agree with the sentiment scores that \n",
    "the dataset's creator assigned to each Tweet. To do so, I examined a pseudo-random sample of ten Tweets and added \n",
    "my own sentiment scores to the sample data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6023ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "sample = df.sample(10, random_state=42) #set the random state to ensure reproducibility\n",
    "sample['OriginalTweet']\n",
    "sample[\"Aren's Sentiment\"] = ['Neutral', 'Neutral', 'Neutral', 'Negative', 'Positive', 'Negative', 'Extremely Negative', 'Positive', 'Neutral', 'Neutral']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc68bf",
   "metadata": {},
   "source": [
    "I then checked them against the scores assigned by the dataset's creator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee83547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ad4a4",
   "metadata": {},
   "source": [
    "As the resulting DataFrame shows, our sentiment scores differ in several places. But how serious are these \n",
    "differences? To assess this, I replaced the categories with numbers and calculated the differences in our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974979b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_values = {\"Extremely Negative\": 0, \"Negative\" : 1, \"Neutral\" : 2, \"Positive\" : 3, \"Extremely Positive\" : 4}\n",
    "sample[\"Sentiment\"].replace(replacement_values, inplace=True)\n",
    "sample[\"Aren's Sentiment\"].replace(replacement_values, inplace=True)\n",
    "sample[\"Difference\"] = np.abs(sample[\"Sentiment\"] - sample[\"Aren's Sentiment\"])\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa45734",
   "metadata": {},
   "source": [
    "Overall there is a mean difference of 1.2 between our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sample['Difference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a89df1",
   "metadata": {},
   "source": [
    "But with such a small sample size, the mean difference is more sensitive to outliers. If, for example, the dataset's creator and I strongly disagree about a small number of cases (like 20152) and one or more of these outliers are present in the sample, then the mean difference would be artificially inflated. To test whether or not this is the case, I've checked how the average mean difference changes as the number of samples increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ee227",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = np.arange(10, 110, 10)\n",
    "\n",
    "variable_sample = df.sample(100, random_state=42)\n",
    "variable_sample[\"Aren's Sentiment\"] = ['Neutral', 'Neutral', 'Neutral', 'Negative', 'Positive', 'Negative', 'Extremely Negative', 'Positive', 'Neutral', 'Neutral', 'Extremely Negative', 'Negative', 'Extremely Negative', 'Neutral', 'Extremely Positive', 'Negative', 'Negative', 'Negative', 'Negative', 'Neutral', 'Extremely Negative', 'Positive', 'Negative', 'Negative', 'Extremely Negative', 'Neutral', 'Extremely Negative', 'Negative', 'Positive', 'Extremely Negative', 'Negative', 'Positive', 'Neutral', 'Negative', 'Negative', 'Positive', 'Extremely Negative', 'Extremely Negative', 'Negative', 'Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Negative', 'Extremely Negative', 'Neutral', 'Negative', 'Extremely Negative', 'Negative', 'Neutral', 'Neutral', 'Negative', 'Positive', 'Negative', 'Neutral', 'Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Neutral', 'Extremely Negative', 'Extremely Negative', 'Negative', 'Positive', 'Extremely Negative', 'Negative', 'Neutral', 'Neutral', 'Positive', 'Positive', 'Extremely Positive', 'Negative', 'Neutral', 'Extremely Negative', 'Neutral', 'Extremely Negative', 'Negative', 'Neutral', 'Negative', 'Positive', 'Neutral', 'Neutral', 'Neutral', 'Positive', 'Positive', 'Negative', 'Neutral', 'Negative', 'Negative', 'Positive', 'Neutral', 'Extremely Negative', 'Extremely Negative', 'Positive', 'Neutral', 'Neutral', 'Positive', 'Neutral', 'Extremely Positive', 'Positive']                                   \n",
    "variable_sample[\"Sentiment\"].replace(replacement_values, inplace=True)\n",
    "variable_sample[\"Aren's Sentiment\"].replace(replacement_values, inplace=True)\n",
    "variable_sample[\"Difference\"] = np.abs(variable_sample[\"Sentiment\"] - variable_sample[\"Aren's Sentiment\"])  \n",
    "\n",
    "mean_diffs = [np.mean(variable_sample.iloc[:size]['Difference']) for size in sample_sizes]\n",
    "\n",
    "plt.plot(sample_sizes, mean_diffs, marker='.')\n",
    "plt.xlabel('Number of sample Tweets')\n",
    "plt.ylabel('Average difference in sentiment score')\n",
    "plt.title('Average difference in sentiment score under increasing sample sizes')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ff6f2",
   "metadata": {},
   "source": [
    "As the chart shows, the mean difference varies back and forth between 1.2 and 1 as the sample size increases, but appears to be converging somewhere 1.075. But what exactly does this mean? Does it indicate compatibility or incompatibility?  \n",
    "\n",
    "We can answer this question by preforming a hypothesis test using 10000 bootstrap resamples of both the 10 tweet and 100 tweet samples. The null hypothesis is that our sentiment scores are fundamentally incompatible (i.e., have a mean difference of 2 or more, which corresponds to a change from negative to positive or vice-versa); the alternative hypothesis is that they are compatible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diffs_10 = np.empty(10000)\n",
    "np.random.seed(42) #set the seed to ensure reproducibility\n",
    "\n",
    "for i in range(10000):\n",
    "    avg_diffs_10[i] = np.mean(np.abs(sample[\"Sentiment\"] - np.random.choice(sample[\"Aren's Sentiment\"], 10)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(avg_diffs_10, bins=100)\n",
    "ax.vlines(2, ymin=0, ymax=1200, color='red', linestyle='--')\n",
    "ax.set_xlabel('Mean difference in sentiment score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of mean differences in sentiment score')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13744a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_diffs_100 = np.empty(10000)\n",
    "np.random.seed(42) #set the seed to ensure reproducibility\n",
    "\n",
    "for i in range(10000):\n",
    "    avg_diffs_100[i] = np.mean(np.abs(variable_sample[\"Sentiment\"] - np.random.choice(variable_sample[\"Aren's Sentiment\"], 100)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(avg_diffs_100, bins=100)\n",
    "ax.vlines(2, ymin=0, ymax=1200, color='red', linestyle='--')\n",
    "ax.set_xlabel('Mean difference in sentiment score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Distribution of mean differences in sentiment score')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569da312",
   "metadata": {},
   "source": [
    "The p value for a mean of 2.0 is low (~.03) for the 10 Tweet sample (indicating that we would expect a mean difference in sentiment score of 2.0 or higher in only 3% of simulations due to natural variability alone.) and extremely low (less than .0001) for the 100 Tweet sample. So I feel fairly confident in rejecting the null hypothesis and using the sentiment scores included in the dataset as a convenient proxy for my\n",
    "own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561bb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "p10 = len(avg_diffs_10[avg_diffs_10 > 2.0])/len(avg_diffs_10)\n",
    "p10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5329c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p100 = len(avg_diffs_100[avg_diffs_100 > 2.0])/len(avg_diffs_100)\n",
    "p100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78bc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659467e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
